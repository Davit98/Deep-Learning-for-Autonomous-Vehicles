{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Classification\n",
    "\n",
    " Implement Linear Classification using pytorch. This consists of having fully connected layers connected one after the other and ReLu activation functions between them.\n",
    " \n",
    " Build a neural network with a minimun of 2 layers in order to do classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1a94ef30e70>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import torch.utils.data as utils\n",
    "import time\n",
    "import pdb\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "torch.manual_seed(1)    # reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "def get_train_valid_loader(data_dir='../data',\n",
    "                           batch_size=64,\n",
    "                           augment=False,\n",
    "                           random_seed = 1,\n",
    "                           valid_size=0.02,\n",
    "                           shuffle=True,\n",
    "                           show_sample=False,\n",
    "                           num_workers=4,\n",
    "                           pin_memory=False):\n",
    "    \"\"\"\n",
    "    Utility function for loading and returning train and valid\n",
    "    multi-process iterators over the CIFAR-10 dataset. A sample\n",
    "    9x9 grid of the images can be optionally displayed.\n",
    "    If using CUDA, num_workers should be set to 1 and pin_memory to True.\n",
    "    Params\n",
    "    ------\n",
    "    - data_dir: path directory to the dataset.\n",
    "    - batch_size: how many samples per batch to load.\n",
    "    - augment: whether to apply the data augmentation scheme\n",
    "      mentioned in the paper. Only applied on the train split.\n",
    "    - random_seed: fix seed for reproducibility.\n",
    "    - valid_size: percentage split of the training set used for\n",
    "      the validation set. Should be a float in the range [0, 1].\n",
    "    - shuffle: whether to shuffle the train/validation indices.\n",
    "    - show_sample: plot 9x9 sample grid of the dataset.\n",
    "    - num_workers: number of subprocesses to use when loading the dataset.\n",
    "    - pin_memory: whether to copy tensors into CUDA pinned memory. Set it to\n",
    "      True if using GPU.\n",
    "    Returns\n",
    "    -------\n",
    "    - train_loader: training set iterator.\n",
    "    - valid_loader: validation set iterator.\n",
    "    \"\"\"\n",
    "    error_msg = \"[!] valid_size should be in the range [0, 1].\"\n",
    "    assert ((valid_size >= 0) and (valid_size <= 1)), error_msg\n",
    "\n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[0.4914, 0.4822, 0.4465],\n",
    "        std=[0.2023, 0.1994, 0.2010],\n",
    "    )\n",
    "\n",
    "    # define transforms\n",
    "    valid_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "    ])\n",
    "    if augment:\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "    else:\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "\n",
    "    # load the dataset\n",
    "    train_dataset = datasets.CIFAR10(\n",
    "        root=data_dir, train=True,\n",
    "        download=True, transform=train_transform,\n",
    "    )\n",
    "\n",
    "    valid_dataset = datasets.CIFAR10(\n",
    "        root=data_dir, train=True,\n",
    "        download=True, transform=valid_transform,\n",
    "    )\n",
    "\n",
    "    num_train = len(train_dataset)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, sampler=train_sampler,\n",
    "        num_workers=num_workers, pin_memory=pin_memory,\n",
    "    )\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset, batch_size=batch_size, sampler=valid_sampler,\n",
    "        num_workers=num_workers, pin_memory=pin_memory,\n",
    "    )\n",
    "\n",
    "    # visualize some images\n",
    "    if show_sample:\n",
    "        sample_loader = torch.utils.data.DataLoader(\n",
    "            train_dataset, batch_size=9, shuffle=shuffle,\n",
    "            num_workers=num_workers, pin_memory=pin_memory,\n",
    "        )\n",
    "        data_iter = iter(sample_loader)\n",
    "        images, labels = data_iter.next()\n",
    "        X = images.numpy().transpose([0, 2, 3, 1])\n",
    "        plot_images(X, labels)\n",
    "\n",
    "    return (train_loader, valid_loader)\n",
    "\n",
    "trainloader, valloader = get_train_valid_loader(num_workers = 1, show_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_output, n_hidden_layers):\n",
    "        super(Net, self).__init__()\n",
    "        # Option 1\n",
    "        self.fc1 = torch.nn.Linear(3072, 1000)\n",
    "        self.fc2 = torch.nn.Linear(1000, 500)\n",
    "        self.fc3 = torch.nn.Linear(500, 100)\n",
    "        self.fc4 = torch.nn.Linear(100, n_output)\n",
    "        \n",
    "        # Option 2\n",
    "#         self.fc_layers = torch.nn.ModuleList([torch.nn.Linear(n_feature, n_hidden)])\n",
    "#         self.fc_layers.extend([torch.nn.Linear(n_hidden, n_hidden) for i in range(0, n_hidden_layers)])\n",
    "#         self.fc_layers.append(torch.nn.Linear(n_hidden, n_output))\n",
    "        \n",
    "#         # Initialize weights\n",
    "#         for layer in self.fc_layers:\n",
    "#             layer.weight.data.normal_(std=0.01)\n",
    "#             layer.bias.data.fill_(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0),-1)\n",
    "        \n",
    "        # Option 1\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        # Option 2\n",
    "#         for layer in self.fc_layers[:-1]:\n",
    "#             x = layer(x)\n",
    "#             x = F.relu(x)\n",
    "            \n",
    "#         x = self.fc_layers[-1](x) # We do not need relu here\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=3072, out_features=1000, bias=True)\n",
      "  (fc2): Linear(in_features=1000, out_features=500, bias=True)\n",
      "  (fc3): Linear(in_features=500, out_features=100, bias=True)\n",
      "  (fc4): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "n_feature = 32 * 32 * 3\n",
    "n_hidden = 100\n",
    "n_classes = 10\n",
    "n_hidden_layers = 1\n",
    "learning_rate = 1e-3\n",
    "\n",
    "net = Net(n_feature=n_feature, n_hidden=n_hidden, n_output=n_classes, n_hidden_layers=n_hidden_layers)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "loss_func = torch.nn.CrossEntropyLoss()  # the target label is NOT an one-hotted\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(dataloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in iter(dataloader):\n",
    "        outputs = net.forward(images)\n",
    "        _, predicted = torch.max(F.softmax(outputs).data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Oganes\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch 0. Accuracy train: 47.565. Accuracy validation: 44.200. Time spent: 45.527\n",
      "Current epoch 1. Accuracy train: 50.006. Accuracy validation: 44.200. Time spent: 46.006\n",
      "Current epoch 2. Accuracy train: 55.996. Accuracy validation: 50.200. Time spent: 45.962\n",
      "Current epoch 3. Accuracy train: 58.653. Accuracy validation: 50.200. Time spent: 46.031\n",
      "Current epoch 4. Accuracy train: 62.049. Accuracy validation: 51.100. Time spent: 48.679\n",
      "Current epoch 5. Accuracy train: 63.433. Accuracy validation: 51.000. Time spent: 47.439\n",
      "Current epoch 6. Accuracy train: 66.408. Accuracy validation: 52.000. Time spent: 45.862\n",
      "Current epoch 7. Accuracy train: 68.533. Accuracy validation: 53.000. Time spent: 46.483\n",
      "Current epoch 8. Accuracy train: 71.233. Accuracy validation: 51.200. Time spent: 47.123\n",
      "Current epoch 9. Accuracy train: 72.651. Accuracy validation: 50.700. Time spent: 46.767\n",
      "Current epoch 10. Accuracy train: 73.149. Accuracy validation: 52.200. Time spent: 47.900\n",
      "Current epoch 11. Accuracy train: 76.600. Accuracy validation: 51.800. Time spent: 46.753\n",
      "Current epoch 12. Accuracy train: 77.529. Accuracy validation: 50.800. Time spent: 47.114\n",
      "Current epoch 13. Accuracy train: 78.482. Accuracy validation: 52.400. Time spent: 48.294\n",
      "Current epoch 14. Accuracy train: 80.020. Accuracy validation: 50.800. Time spent: 47.013\n",
      "Current epoch 15. Accuracy train: 81.069. Accuracy validation: 52.300. Time spent: 48.524\n",
      "Current epoch 16. Accuracy train: 82.147. Accuracy validation: 50.500. Time spent: 48.760\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-103c3a376a2c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m# Test accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    101\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m                     \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "accuracy_train = []\n",
    "accuracy_val = []\n",
    "\n",
    "for cur_epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    # Train\n",
    "    for images, labels in iter(trainloader):\n",
    "        optimizer.zero_grad()\n",
    "        predicted = net.forward(images)\n",
    "        loss = loss_func(predicted, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # Test accuracy\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        accuracy_train.append(get_accuracy(trainloader)) # Test on train data\n",
    "        accuracy_val.append(get_accuracy(valloader)) # Test on validation data\n",
    "                \n",
    "    time_spent = time.time() - start\n",
    "    start = time.time()\n",
    "    \n",
    "    print(f\"Current epoch {cur_epoch}. Accuracy train: {accuracy_train[-1]:.3f}. \"\n",
    "          f\"Accuracy validation: {accuracy_val[-1]:.3f}. Time spent: {time_spent:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 200 features 3 layers\n",
    "plt.figure()\n",
    "plt.plot(range(epochs), accuracy_train, label=\"Train\")\n",
    "plt.plot(range(epochs), accuracy_test, label=\"Test\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Oganes\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch 0. Accuracy of the network: 44.8. Time spent: 65.94373059272766\n",
      "Current epoch 1. Accuracy of the network: 44.5. Time spent: 69.2902467250824\n",
      "Current epoch 2. Accuracy of the network: 48.1. Time spent: 73.7737467288971\n",
      "Current epoch 3. Accuracy of the network: 50.1. Time spent: 76.23479843139648\n",
      "Current epoch 4. Accuracy of the network: 50.6. Time spent: 73.8637022972107\n",
      "Current epoch 5. Accuracy of the network: 50.3. Time spent: 72.9415111541748\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-29d0100e3755>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-0d2db39d1294>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc_layers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# We do not need relu here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1368\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1370\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1371\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#traindataset = utils.TensorDataset(X_train, y_train)\n",
    "#trainloader = utils.DataLoader(traindataset, batch_size=64, shuffle=True)\n",
    "\n",
    "epochs = 10\n",
    "accuracy_per_epoch = []\n",
    "\n",
    "for cur_epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    # Train\n",
    "    for images, labels in iter(trainloader):\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        predicted = net.forward(images)\n",
    "        loss = loss_func(predicted, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # Test accuracy\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in iter(valloader):\n",
    "            outputs = net.forward(images)\n",
    "            _, predicted = torch.max(F.softmax(outputs).data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        accuracy = 100 * correct / total\n",
    "                \n",
    "    time_spent = time.time() - start\n",
    "    start = time.time()\n",
    "    accuracy_per_epoch.append(accuracy)\n",
    "    \n",
    "    print(f\"Current epoch {cur_epoch}. Accuracy of the network: {accuracy}. Time spent: {time_spent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, the model should be saved to be tested on the test dataset or to be used in a real-life application. To save a model in pytorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load a pretrained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"PATH_TO_SAVED_MODEL\")\n",
    "net.load_state_dict(checkpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
